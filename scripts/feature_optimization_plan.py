#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–æ–¹æ¡ˆ
åŸºäºç‰¹å¾é‡è¦æ€§åˆ†æç»“æœï¼Œé‡ç‚¹å¼€å‘æ³¢åŠ¨ç‡å’Œè¶‹åŠ¿ç‰¹å¾
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class AdvancedFeatureOptimizer:
    def __init__(self):
        self.optimization_results = {}
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“Š åŠ è½½åŸå§‹ç‰¹å¾æ•°æ®...")
        data = pd.read_csv('data/processed_features.csv')
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")
        return data
    
    def create_enhanced_volatility_features(self, data):
        """åˆ›å»ºå¢å¼ºæ³¢åŠ¨ç‡ç‰¹å¾"""
        print("ğŸŒŠ åˆ›å»ºå¢å¼ºæ³¢åŠ¨ç‡ç‰¹å¾...")
        
        # å¤šçª—å£æ³¢åŠ¨ç‡
        for window in [5, 10, 20, 60]:
            data[f'volatility_std_{window}'] = data['close'].rolling(window).std()
            data[f'volatility_range_{window}'] = (data['high'] - data['low']).rolling(window).mean()
        
        # æ»åæ³¢åŠ¨ç‡ç‰¹å¾
        for lag in [1, 5, 10, 20]:
            data[f'volatility_std_20_lag{lag}'] = data['volatility_std_20'].shift(lag)
        
        # æ³¢åŠ¨ç‡æ¯”ç‡
        data['volatility_ratio_short_long'] = data['volatility_std_5'] / (data['volatility_std_20'] + 1e-8)
        data['volatility_ratio_medium_long'] = data['volatility_std_10'] / (data['volatility_std_60'] + 1e-8)
        
        # æ³¢åŠ¨ç‡åˆ¶åº¦æ£€æµ‹
        data['volatility_regime'] = self._detect_volatility_regime(data['volatility_std_20'])
        
        # æ³¢åŠ¨ç‡çªç ´
        data['volatility_breakout'] = (data['volatility_std_5'] > data['volatility_std_20'].rolling(20).quantile(0.8)).astype(int)
        
        return data
    
    def _detect_volatility_regime(self, volatility):
        """æ£€æµ‹æ³¢åŠ¨ç‡åˆ¶åº¦"""
        # è®¡ç®—åˆ†ä½æ•°
        q33 = volatility.rolling(252).quantile(0.33)
        q67 = volatility.rolling(252).quantile(0.67)
        
        regime = pd.Series(1, index=volatility.index)  # ä¸­ç­‰æ³¢åŠ¨ç‡
        regime[volatility <= q33] = 0  # ä½æ³¢åŠ¨ç‡
        regime[volatility >= q67] = 2  # é«˜æ³¢åŠ¨ç‡
        
        return regime
    
    def create_enhanced_trend_features(self, data):
        """åˆ›å»ºå¢å¼ºè¶‹åŠ¿ç‰¹å¾"""
        print("ğŸ“ˆ åˆ›å»ºå¢å¼ºè¶‹åŠ¿ç‰¹å¾...")
        
        # å¤šæ—¶é—´æ¡†æ¶ç§»åŠ¨å¹³å‡
        for window in [10, 20, 50, 100, 200]:
            data[f'sma_{window}'] = data['close'].rolling(window).mean()
            data[f'ema_{window}'] = data['close'].ewm(span=window).mean()
            data[f'sma_{window}_norm'] = data['close'] / data[f'sma_{window}'] - 1
        
        # è¶‹åŠ¿æ–œç‡
        for window in [10, 20, 50]:
            data[f'trend_slope_{window}'] = data[f'sma_{window}'].diff(5) / data[f'sma_{window}'].shift(5)
        
        # è¶‹åŠ¿ä¸€è‡´æ€§
        data['trend_consistency'] = (
            (data['sma_10'] > data['sma_20']).astype(int) +
            (data['sma_20'] > data['sma_50']).astype(int) +
            (data['sma_50'] > data['sma_100']).astype(int)
        )
        
        # å¢å¼ºMACD
        data['macd_histogram_change'] = data['macd_12_26_9'].diff()
        data['macd_signal_cross'] = ((data['macd_12_26_9'] > 0) & (data['macd_12_26_9'].shift(1) <= 0)).astype(int)
        
        # åè½¬æ£€æµ‹
        data['trend_reversal'] = self._detect_trend_reversal(data)
        
        return data
    
    def _detect_trend_reversal(self, data):
        """æ£€æµ‹è¶‹åŠ¿åè½¬"""
        # åŸºäºä»·æ ¼å’Œç§»åŠ¨å¹³å‡çš„åè½¬ä¿¡å·
        reversal = pd.Series(0, index=data.index)
        
        # ä¸Šå‡è¶‹åŠ¿åè½¬
        up_reversal = (
            (data['close'] < data['sma_20']) & 
            (data['close'].shift(1) >= data['sma_20'].shift(1)) &
            (data['sma_20'] > data['sma_20'].shift(5))
        )
        
        # ä¸‹é™è¶‹åŠ¿åè½¬
        down_reversal = (
            (data['close'] > data['sma_20']) & 
            (data['close'].shift(1) <= data['sma_20'].shift(1)) &
            (data['sma_20'] < data['sma_20'].shift(5))
        )
        
        reversal[up_reversal] = -1  # å‘ä¸‹åè½¬
        reversal[down_reversal] = 1   # å‘ä¸Šåè½¬
        
        return reversal
    
    def create_enhanced_price_features(self, data):
        """åˆ›å»ºå¢å¼ºä»·æ ¼ç‰¹å¾"""
        print("ğŸ’° åˆ›å»ºå¢å¼ºä»·æ ¼ç‰¹å¾...")
        
        # ä»·æ ¼ä½ç½®
        for window in [20, 50, 100]:
            high_roll = data['high'].rolling(window).max()
            low_roll = data['low'].rolling(window).min()
            data[f'price_position_{window}'] = (data['close'] - low_roll) / (high_roll - low_roll + 1e-8)
        
        # ä»·æ ¼åŒºé—´
        for window in [5, 10, 20]:
            data[f'price_range_rolling_{window}'] = (data['high'] - data['low']).rolling(window).mean()
            data[f'price_range_norm_{window}'] = data[f'price_range_rolling_{window}'] / data['close']
        
        # è·³ç©ºæ£€æµ‹
        data['gap_up'] = ((data['open'] > data['high'].shift(1)) & (data['open'] > data['close'].shift(1))).astype(int)
        data['gap_down'] = ((data['open'] < data['low'].shift(1)) & (data['open'] < data['close'].shift(1))).astype(int)
        
        # ä»·æ ¼åŠ¨é‡
        for period in [5, 10, 20]:
            data[f'price_momentum_{period}'] = data['close'].pct_change(period)
            data[f'price_acceleration_{period}'] = data[f'price_momentum_{period}'].diff()
        
        return data
    
    def create_market_microstructure_features(self, data):
        """åˆ›å»ºå¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾"""
        print("ğŸ”¬ åˆ›å»ºå¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾...")
        
        # VWAPç›¸å…³
        if 'volume' in data.columns:
            data['vwap'] = (data['close'] * data['volume']).rolling(20).sum() / data['volume'].rolling(20).sum()
            data['vwap_deviation'] = (data['close'] - data['vwap']) / data['vwap']
            
            # æˆäº¤é‡æ¯”ç‡
            data['volume_ratio'] = data['volume'] / data['volume'].rolling(20).mean()
            data['volume_price_trend'] = data['volume'].rolling(5).corr(data['close'].rolling(5))
        
        # ä»·æ ¼-æˆäº¤é‡èƒŒç¦»
        if 'volume' in data.columns:
            price_change = data['close'].pct_change(5)
            volume_change = data['volume'].pct_change(5)
            data['price_volume_divergence'] = np.sign(price_change) != np.sign(volume_change)
        
        # ä»·æ ¼æ•ˆç‡
        for window in [10, 20]:
            price_change = abs(data['close'].diff(window))
            path_length = abs(data['close'].diff()).rolling(window).sum()
            data[f'price_efficiency_{window}'] = price_change / (path_length + 1e-8)
        
        # AmihudéæµåŠ¨æ€§æŒ‡æ ‡
        if 'volume' in data.columns:
            daily_return = abs(data['close'].pct_change())
            dollar_volume = data['close'] * data['volume']
            data['amihud_illiquidity'] = daily_return / (dollar_volume + 1e-8)
        
        return data
    
    def optimize_features(self, data):
        """æ‰§è¡Œç‰¹å¾ä¼˜åŒ–"""
        print("ğŸš€ å¼€å§‹ç‰¹å¾ä¼˜åŒ–...")
        print("=" * 50)
        
        original_shape = data.shape
        
        # åˆ›å»ºå„ç±»å¢å¼ºç‰¹å¾
        data = self.create_enhanced_volatility_features(data)
        data = self.create_enhanced_trend_features(data)
        data = self.create_enhanced_price_features(data)
        data = self.create_enhanced_microstructure_features(data)
        
        # ç§»é™¤æ— é™å€¼å’ŒNaN
        data = data.replace([np.inf, -np.inf], np.nan)
        
        final_shape = data.shape
        new_features = final_shape[1] - original_shape[1]
        
        print(f"âœ… ç‰¹å¾ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“Š åŸå§‹ç‰¹å¾æ•°: {original_shape[1]}")
        print(f"ğŸ“Š æ–°å¢ç‰¹å¾æ•°: {new_features}")
        print(f"ğŸ“Š æœ€ç»ˆç‰¹å¾æ•°: {final_shape[1]}")
        
        return data
    
    def generate_optimization_report(self, original_shape, final_shape):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'optimization_summary': {
                'original_features': original_shape[1],
                'new_features': final_shape[1] - original_shape[1],
                'total_features': final_shape[1],
                'samples': final_shape[0]
            },
            'feature_categories': {
                'volatility_features': {
                    'description': 'å¢å¼ºæ³¢åŠ¨ç‡ç‰¹å¾ï¼ŒåŒ…æ‹¬å¤šçª—å£ã€æ»åã€æ¯”ç‡å’Œåˆ¶åº¦æ£€æµ‹',
                    'expected_improvement': 'æé«˜å¯¹å¸‚åœºæ³¢åŠ¨çš„æ•æ„Ÿæ€§å’Œé¢„æµ‹èƒ½åŠ›'
                },
                'trend_features': {
                    'description': 'å¢å¼ºè¶‹åŠ¿ç‰¹å¾ï¼ŒåŒ…æ‹¬å¤šæ—¶é—´æ¡†æ¶ç§»åŠ¨å¹³å‡å’Œè¶‹åŠ¿åˆ†æ',
                    'expected_improvement': 'æ›´å¥½åœ°æ•æ‰å¸‚åœºè¶‹åŠ¿å˜åŒ–å’Œåè½¬ä¿¡å·'
                },
                'price_features': {
                    'description': 'å¢å¼ºä»·æ ¼ç‰¹å¾ï¼ŒåŒ…æ‹¬ä½ç½®ã€åŒºé—´ã€è·³ç©ºå’ŒåŠ¨é‡æŒ‡æ ‡',
                    'expected_improvement': 'æé«˜å¯¹ä»·æ ¼è¡Œä¸ºæ¨¡å¼çš„è¯†åˆ«èƒ½åŠ›'
                },
                'microstructure_features': {
                    'description': 'å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾ï¼ŒåŒ…æ‹¬VWAPã€æˆäº¤é‡å’ŒæµåŠ¨æ€§æŒ‡æ ‡',
                    'expected_improvement': 'å¢å¼ºå¯¹å¸‚åœºå¾®è§‚ç»“æ„çš„ç†è§£å’Œé¢„æµ‹'
                }
            },
            'next_steps': [
                '1. æ³¢åŠ¨ç‡ç‰¹å¾ä¼˜åŒ–ï¼ˆ1å‘¨å†…ï¼‰',
                '2. è¶‹åŠ¿ç‰¹å¾å¢å¼ºï¼ˆ1å‘¨å†…ï¼‰',
                '3. ä»·æ ¼ç‰¹å¾æ”¹è¿›ï¼ˆ2å‘¨å†…ï¼‰',
                '4. å¾®è§‚ç»“æ„ç‰¹å¾ï¼ˆ3å‘¨å†…ï¼‰'
            ]
        }
        
        return report
    
    def save_results(self, data, report):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜ä¼˜åŒ–ç»“æœ...")
        
        os.makedirs('output', exist_ok=True)
        
        # ä¿å­˜ä¼˜åŒ–åçš„æ•°æ®
        data.to_csv('output/optimized_features_data.csv', index=False)
        
        # ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š
        with open('output/feature_optimization_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print("âœ… ç»“æœå·²ä¿å­˜åˆ° output/ ç›®å½•")

def main():
    print("ğŸ¯ ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–æ–¹æ¡ˆå®æ–½")
    print("=" * 50)
    
    optimizer = AdvancedFeatureOptimizer()
    
    try:
        # åŠ è½½æ•°æ®
        data = optimizer.load_data()
        original_shape = data.shape
        
        # æ‰§è¡Œä¼˜åŒ–
        optimized_data = optimizer.optimize_features(data)
        final_shape = optimized_data.shape
        
        # ç”ŸæˆæŠ¥å‘Š
        report = optimizer.generate_optimization_report(original_shape, final_shape)
        
        # ä¿å­˜ç»“æœ
        optimizer.save_results(optimized_data, report)
        
        # æ‰“å°æ€»ç»“
        print("\nğŸ“Š ç‰¹å¾ä¼˜åŒ–æ€»ç»“:")
        for category, info in report['feature_categories'].items():
            print(f"âœ… {category}: {info['expected_improvement']}")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’:")
        for step in report['next_steps']:
            print(f"  {step}")
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()